{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import jax\n",
    "from math import log, exp, sqrt\n",
    "from sim import sim_and_fit, sim_wf\n",
    "\n",
    "# from estimate import posterior_decoding, sample_paths\n",
    "from common import Observation\n",
    "from plotting import plot_summary, compute_rmse, bias_variance\n",
    "from itertools import combinations_with_replacement, product\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "N_SIMULATIONS = 100\n",
    "N_EM_ITERATIONS = 3\n",
    "set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-canyon",
   "metadata": {},
   "source": [
    "## Define standard models for demography and selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mdls = [\n",
    "    {\"s\": [0.01] * 100, \"h\": [0.5] * 100, \"f0\": 0.1},\n",
    "    #    {\"s\": [0.02] * 50 + [-0.02] * 50, \"h\": [0.5] * 100, \"f0\": 0.1},\n",
    "    {\n",
    "        \"s\": [0.02 * np.cos(np.pi * x / 99) for x in range(100)],\n",
    "        \"h\": [0.5] * 100,\n",
    "        \"f0\": 0.1,\n",
    "    },\n",
    "    {\"s\": (([0.02] * 20 + [-0.02] * 20) * 3)[:100], \"h\": [0.5] * 100, \"f0\": 0.5},\n",
    "]\n",
    "s_names = [\"const\", \"switch\", \"fluc\"]\n",
    "\n",
    "gr = exp(log(10) / 100)\n",
    "Ne_mdls = [\n",
    "    [10000] * 100,  # constant\n",
    "    [round(10000 * gr ** (10 * int(x / 10))) for x in range(100)],  # exp growth\n",
    "    [10000] * 40 + [1000] * 20 + [10000] * 40,  # bottleneck\n",
    "]\n",
    "Ne_names = [\"const\", \"exp\", \"bottle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-custody",
   "metadata": {},
   "source": [
    "## Performance under standard models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=4, figsize=(12, 12))\n",
    "\n",
    "axs[0][0].axis(\"off\")\n",
    "\n",
    "optimal_lambda = [5, 4, 3]\n",
    "\n",
    "std_res = pd.DataFrame(columns=[\"Scenario\", \"Demog\", \"Select\", \"iter\", \"RMSE\"])\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i + 1][0].plot(range(1, 101), Ne_mdls[i], color=\"black\")\n",
    "\n",
    "for j in range(3):\n",
    "    axs[0][j + 1].plot(range(1, 101), s_mdls[j][\"s\"], color=\"black\")\n",
    "\n",
    "std_res = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        res = []\n",
    "        for seed in range(N_SIMULATIONS):\n",
    "            this_res = sim_and_fit(\n",
    "                s_mdls[j],\n",
    "                seed=12345 + seed,\n",
    "                lam=10 ** optimal_lambda[j],\n",
    "                Ne=Ne_mdls[i],\n",
    "                em_iterations=N_EM_ITERATIONS,\n",
    "            )\n",
    "            res.append(this_res)\n",
    "            rmse = compute_rmse(this_res[\"s_hat\"], s_mdls[i][\"s\"])\n",
    "            std_res.append(\n",
    "                {\n",
    "                    \"s_mdl\": s_names[i],\n",
    "                    \"Ne_mdl\": Ne_names[i],\n",
    "                    \"iter\": seed,\n",
    "                    \"sampling\": \"100-10\",\n",
    "                    \"rmse\": rmse,\n",
    "                }\n",
    "            )\n",
    "        x, y = zip(*[(range(len(rr[\"s_hat\"])), rr[\"s_hat\"]) for rr in res])\n",
    "        plot_summary(axs[i + 1][j + 1], x, y, s_mdls[j][\"s\"])\n",
    "\n",
    "std_res = pd.DataFrame(std_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-kazakhstan",
   "metadata": {},
   "source": [
    "## Performance if we incorrectly assume that Ne is constant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=3, figsize=(12, 9))\n",
    "\n",
    "axs[0][0].axis(\"off\")\n",
    "optimal_lambda = [5, 4, 3]\n",
    "\n",
    "for i in range(1, 3):\n",
    "    axs[i][0].plot(range(1, 101), Ne_mdls[i], color=\"black\")\n",
    "\n",
    "for j in range(3):\n",
    "    axs[0][j + 1].plot(range(1, 101), s_mdls[j][\"s\"], color=\"black\")\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(1, 3):\n",
    "        res = []\n",
    "        for seed in range(N_SIMULATIONS):\n",
    "            res.append(\n",
    "                sim_and_fit(\n",
    "                    s_mdls[i],\n",
    "                    seed=12345 + seed,\n",
    "                    lam=10 ** optimal_lambda[i],\n",
    "                    Ne=Ne_mdls[j],\n",
    "                    Ne_fit=[10000] * len(s_mdls[i][\"s\"]),\n",
    "                    em_iterations=N_EM_ITERATIONS,\n",
    "                )\n",
    "            )\n",
    "        x, y = zip(*[(range(len(rr[\"s_hat\"])), rr[\"s_hat\"]) for rr in res])\n",
    "        plot_summary(axs[j][i + 1], x, y, s_mdls[i][\"s\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-individual",
   "metadata": {},
   "source": [
    "## See how RMSE changes as sample size and frequency change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 10, 100]\n",
    "ks = [5, 10, 20]\n",
    "size_res = []  # total results to save\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, nrows=4, figsize=(12, 12))\n",
    "optimal_lambda = [5, 4, 3]\n",
    "\n",
    "axs[0][0].axis(\"off\")\n",
    "std_res = pd.DataFrame(columns=[\"Scenario\", \"Demog\", \"Select\", \"iter\", \"RMSE\"])\n",
    "for i in range(3):\n",
    "    axs[i + 1][0].plot(range(1, 101), Ne_mdls[i], color=\"black\")\n",
    "for j in range(3):\n",
    "    axs[0][j + 1].plot(range(1, 101), s_mdls[j][\"s\"], color=\"black\")\n",
    "\n",
    "\n",
    "for i, j in product(range(3), range(3)):\n",
    "    plot_res = []  # results to make this subplot\n",
    "    for nn, kk, seed in product(ns, ks, range(N_SIMULATIONS)):\n",
    "        this_res = sim_and_fit(\n",
    "            s_mdls[j],\n",
    "            seed=12345 + seed,\n",
    "            lam=10 ** optimal_lambda[j],\n",
    "            Ne=Ne_mdls[i],\n",
    "            n=nn,\n",
    "            k=kk,\n",
    "            em_iterations=N_EM_ITERATIONS,\n",
    "        )\n",
    "        rmse = compute_rmse(this_res[\"s_hat\"], s_mdls[j][\"s\"])\n",
    "        plot_res.append(\n",
    "            {\n",
    "                \"s_mdl\": s_names[j],\n",
    "                \"Ne_mdl\": Ne_names[j],\n",
    "                \"iter\": seed,\n",
    "                \"sampling\": str(nn) + \"-\" + str(kk),\n",
    "                \"rmse\": rmse,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    size_res.extend(plot_res)\n",
    "    plot_res = pd.DataFrame(plot_res)\n",
    "    axs[i + 1][j + 1].tick_params(labelsize=6)\n",
    "    axs[i + 1][j + 1].xaxis.label.set_visible(False)\n",
    "    axs[i + 1][j + 1].title.set_visible(False)\n",
    "    plot_res.boxplot(ax=axs[i + 1][j + 1], by=\"sampling\", column=[\"rmse\"])\n",
    "\n",
    "fig.suptitle(None)\n",
    "size_res = pd.DataFrame(size_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-performance",
   "metadata": {},
   "source": [
    "## Smoothing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_lambda = [1, 2, 2.5, 3, 3.5, 4, 4.5, 5, 6]\n",
    "lam_res = []  # total results to save\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, nrows=4, figsize=(12, 12))\n",
    "\n",
    "axs[0][0].axis(\"off\")\n",
    "std_res = pd.DataFrame(columns=[\"Scenario\", \"Demog\", \"Select\", \"iter\", \"RMSE\"])\n",
    "for i in range(3):\n",
    "    axs[i + 1][0].plot(range(1, 101), Ne_mdls[i], color=\"black\")\n",
    "for j in range(3):\n",
    "    axs[0][j + 1].plot(range(1, 101), s_mdls[j][\"s\"], color=\"black\")\n",
    "\n",
    "lam_res = []\n",
    "for i, j in product(range(3), range(3)):\n",
    "    plot_res = []  # results to make this subplot\n",
    "    for lam in log10_lambda:\n",
    "        this_res = []\n",
    "        for seed in range(N_SIMULATIONS):\n",
    "            this_res.append(\n",
    "                sim_and_fit(\n",
    "                    s_mdls[j],\n",
    "                    seed=12345 + seed,\n",
    "                    lam=10 ** lam,\n",
    "                    Ne=Ne_mdls[i],\n",
    "                    em_iterations=N_EM_ITERATIONS,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        x, y = zip(*[(range(len(rr[\"s_hat\"])), rr[\"s_hat\"]) for rr in this_res])\n",
    "        b, v, m = bias_variance(y, s_mdls[j][\"s\"])\n",
    "        plot_res.append(\n",
    "            {\n",
    "                \"s_mdl\": s_names[j],\n",
    "                \"Ne_mdl\": Ne_names[j],\n",
    "                \"lambda\": lam,\n",
    "                \"rmse\": m,\n",
    "                \"rbias\": b,\n",
    "                \"rvar\": v,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    lam_res.extend(plot_res)\n",
    "    plot_res = pd.DataFrame(plot_res)\n",
    "    axs[i + 1][j + 1].tick_params(labelsize=6)\n",
    "    axs[i + 1][j + 1].xaxis.label.set_visible(False)\n",
    "    axs[i + 1][j + 1].title.set_visible(False)\n",
    "    axs[i + 1][j + 1].plot(plot_res[\"lambda\"], plot_res[\"rmse\"], color=\"tab:red\")\n",
    "    axs[i + 1][j + 1].plot(plot_res[\"lambda\"], plot_res[\"rbias\"], color=\"tab:green\")\n",
    "    axs[i + 1][j + 1].plot(plot_res[\"lambda\"], plot_res[\"rvar\"], color=\"tab:blue\")\n",
    "\n",
    "\n",
    "fig.suptitle(None)\n",
    "lam_res = pd.DataFrame(lam_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-program",
   "metadata": {},
   "source": [
    "## Simulations using the sampling distribution of the ancient European samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv(\"allbrit.meta\", sep=\"\\t\")\n",
    "samples[\"GenBP\"] = samples.DateBP // 29  # assume 29 years per-generation\n",
    "counts = samples.GenBP.value_counts().sort_index()\n",
    "sizes, times = counts.values, np.array(counts.index)\n",
    "\n",
    "T = times[-1]\n",
    "s2_mdls = [\n",
    "    {\"s\": [0.01] * T, \"h\": [0.5] * T, \"f0\": 0.1},\n",
    "    {\n",
    "        \"s\": [0.02 * np.cos(np.pi * x / (T - 1)) for x in range(T)],\n",
    "        \"h\": [0.5] * T,\n",
    "        \"f0\": 0.1,\n",
    "    },\n",
    "    {\"s\": (([0.02] * 20 + [-0.02] * 20) * 6)[:T], \"h\": [0.5] * T, \"f0\": 0.5},\n",
    "]\n",
    "gr = exp(log(100) / T)\n",
    "Ne_mdl2 = [round(10000 * gr ** (10 * int(x / 10))) for x in range(T)]  # exp growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(12, 6))\n",
    "\n",
    "optimal_lambda = [5, 4, 2]\n",
    "\n",
    "\n",
    "for j in range(3):\n",
    "    res = []\n",
    "    for seed in range(N_SIMULATIONS):\n",
    "        this_res = sim_and_fit(s2_mdls[j], seed=12345 + seed, lam=10**optimal_lambda[j], Ne=Ne_mdl2, k=times, n=sizes)\n",
    "        res.append(this_res)\n",
    "    x, y = zip(*[(range(len(rr[\"s_hat\"])), rr[\"s_hat\"]) for rr in res])\n",
    "    plot_summary(axs[0][j], x, y, s2_mdls[j][\"s\"])\n",
    "\n",
    "log10_lambda = [1, 2, 2.5, 3, 3.5, 4, 4.5, 5, 6]\n",
    "\n",
    "for j in range(3):\n",
    "    plot_res = []  # results to make this subplot\n",
    "    for lam in log10_lambda:\n",
    "        this_res = []\n",
    "        for seed in range(N_SIMULATIONS):\n",
    "            this_res.append(\n",
    "                sim_and_fit(s2_mdls[j], seed=12345 + seed, lam=10 ** lam, Ne=10000, k=times, n=sizes,em_iterations=N_EM_ITERATIONS)\n",
    "            )\n",
    "\n",
    "        x, y = zip(*[(range(len(rr[\"s_hat\"])), rr[\"s_hat\"]) for rr in this_res])\n",
    "        b, v, m = bias_variance(y, s2_mdls[j][\"s\"])\n",
    "        plot_res.append(\n",
    "            {\n",
    "                \"s_mdl\": s_names[j],\n",
    "                \"Ne_mdl\": \"Exp2\",\n",
    "                \"lambda\": lam,\n",
    "                \"rmse\": m,\n",
    "                \"rbias\": b,\n",
    "                \"rvar\": v,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    plot_res = pd.DataFrame(plot_res)\n",
    "    axs[1][j].tick_params(labelsize=6)\n",
    "    axs[1][j].xaxis.label.set_visible(False)\n",
    "    axs[1][j].title.set_visible(False)\n",
    "    axs[1][j].plot(plot_res[\"lambda\"], plot_res[\"rmse\"], color=\"tab:red\")\n",
    "    axs[1][j].plot(plot_res[\"lambda\"], plot_res[\"rbias\"], color=\"tab:green\")\n",
    "    axs[1][j].plot(plot_res[\"lambda\"], plot_res[\"rvar\"], color=\"tab:blue\")\n",
    "\n",
    "\n",
    "fig.suptitle(None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
